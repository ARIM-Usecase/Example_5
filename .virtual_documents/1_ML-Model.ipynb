








!git clone https://github.com/ARIM-Usecase/Example_5.git
%cd Example_5





#汎用ライブラリ
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#前処理
from sklearn.utils import shuffle
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

# 機械学習モデル
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor
import xgboost
import lightgbm
import catboost

# モデル評価
from scipy.stats import pearsonr
from sklearn.model_selection import cross_val_score
from sklearn.metrics import make_scorer
from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error





# データのインポート
data_train = shuffle(pd.read_excel("./data/data_all_train.xlsx"))
data_train


data_test = pd.read_excel("./data/data_all_test.xlsx")





#説明変数と目的変数および訓練データと検証データ
X_train = data_train.drop(["Abs"], axis=1)
y_train = data_train["Abs"]
X_test = data_test.drop(["Abs"], axis=1)
y_test = data_test["Abs"]





# 相関行列の作成とヒートマップの表示
def plot_correlation_heatmap(data):
    corr_mat = data.corr()
    
    plt.figure(figsize=(9.5, 7.5))
    
    sns.heatmap(corr_mat, 
                vmax=.8, 
                square=True, 
                cmap="GnBu_r", 
                annot=True, 
                annot_kws={'size': 12, 'weight': 'bold'}, 
                fmt='.2f', 
                linecolor='white', 
                linewidths=1
               )
    
    plt.xticks(rotation=360, fontproperties='Times New Roman', size=24, weight='black')
    plt.yticks(rotation=360, fontproperties='Times New Roman', size=24, weight='black')
    plt.tick_params(width=3, length=8)
    
    plt.savefig("./output/correlation.png", dpi=300)
    plt.show()


plot_correlation_heatmap(data_train.iloc[:, :-1])





# 評価指標の計算

def evaluate_model(model, X_train, y_train, X_test, y_test, model_name):
    pred_train = model.predict(X_train)
    pred_test = model.predict(X_test)

    pearson_train = np.corrcoef(y_train, pred_train)[0, 1]
    pearson_test = np.corrcoef(y_test, pred_test)[0, 1]

    MAPE_train = mean_absolute_percentage_error(y_train, pred_train)
    RMSE_train = np.sqrt(mean_squared_error(y_train, pred_train))
    MAE_train = mean_absolute_error(y_train, pred_train)

    MAPE_test = mean_absolute_percentage_error(y_test, pred_test)
    RMSE_test = np.sqrt(mean_squared_error(y_test, pred_test))
    MAE_test = mean_absolute_error(y_test, pred_test)

    print(f"{model_name} Pearson Coeffient train:", pearson_train)
    print(f"{model_name} Pearson Coeffient test:", pearson_test)
    print(f"{model_name} MAPE_train:", MAPE_train)
    print(f"{model_name} RMSE_train:", RMSE_train)
    print(f"{model_name} MAE_train:", MAE_train)
    print(f"{model_name} MAPE_test:", MAPE_test)
    print(f"{model_name} RMSE_test:", RMSE_test)
    print(f"{model_name} MAE_test:", MAE_test)
    return pred_test





models = {
    "KNN": KNeighborsRegressor(5),
    "RandomForest": RandomForestRegressor(n_estimators=60),
    "ExtraTrees": ExtraTreesRegressor(n_estimators=15),
    "GBDT": GradientBoostingRegressor(n_estimators=55),
    "XGBoost": xgboost.XGBRegressor(n_estimators=300),
    "LightGBM": lightgbm.LGBMRegressor(objective='regression', num_leaves=40, learning_rate=0.02, n_estimators=400),
    "CatBoost": catboost.CatBoostRegressor(iterations=500, learning_rate=0.01, loss_function='RMSE', verbose=False)
}





for name, model in models.items():
    model.fit(X_train, y_train)
    pred_test = evaluate_model(model, X_train, y_train, X_test, y_test, name)





# Custom scorer for cross-validation
def pearson_correlation(y_true, y_pred):
    return pearsonr(y_true, y_pred)[0]


# データを保持するリストを準備
results = []

# Cross-validation for all models
for name, model in models.items():
    pipeline = make_pipeline(StandardScaler(), model)
    scores = cross_val_score(pipeline, X_train, y_train, scoring=make_scorer(pearson_correlation), cv=10, n_jobs=1)
    
    # モデルの結果をリストに保存
    results.append({
        'Model': name,
        'Cross Validation Mean': np.mean(scores),
        'Cross Validation Std': np.std(scores),
        'Cross Validation Scores': scores
    })

    print(f"Model: {name}")
    print('Cross Validation scores: %s' % scores)
    print('Cross Validation: %.8f +/- %.8f' % (np.mean(scores), np.std(scores)))


# DataFrameに変換
df_results = pd.DataFrame(results)
df_results





best_model = df_results.loc[df_results['Cross Validation Mean'].idxmax()]

print("\nBest Model:")
print(best_model)











# モデルの学習
rfr = RandomForestRegressor(n_estimators=60)
rfr.fit(X_train, y_train)





# 特徴量重要度の抽出
feature_importance = pd.Series(rfr.feature_importances_, index=X_train.columns)
feature_importance








x = [r'$\mathregular{WL}$', r'$\mathregular{B}$', r'$\mathregular{G}$', r'$\mathregular{R}$']
y = feature_importance.values





# 特徴量の可視化設定

def plot_feature_importance(importance, labels, filename='feature_importance.png'):
    plt.figure(figsize=(10, 8))
    ax = plt.gca()

    # 軸の線幅設定
    for spine in ax.spines.values():
        spine.set_linewidth(2.0)

    # barプロット作図
    plt.bar(labels, importance, color='blue')

    # フォントとラベルの設定
    plt.yticks(fontproperties='Times New Roman', size=24, weight='black')
    plt.xticks(fontproperties='Times New Roman', size=24, weight='black')
    plt.tick_params(axis='y', width=2, length=6)
    plt.tick_params(axis='x', width=2, length=6)
    
    plt.xlabel('Descriptors', fontdict={'family': 'Times New Roman', 'weight': 'black', 'size': 28})
    plt.ylabel('Feature Importance', fontdict={'family': 'Times New Roman', 'weight': 'black', 'size': 28})

    plt.ylim(0, 0.6)
    
    # プロットの保存と表示
    plt.savefig(filename, dpi=300)
    plt.show()


# プロット作成
plot_feature_importance(y, x)



